#!__BASH__

OUTPUT=/dev/stdout

exit_program()
{
  echo "USAGE: $1 webdir"
  echo "WHERE"
  echo "   webdir   folder downloaded directories"
  exit 1
}

langs=""
FILE="/dev/stdin"

ARGS=$(getopt "hl:" $*)

set -- $ARGS
for i
do
  case "$i" in
    -h|--help)
      exit_program $(basename $0)
      ;;
    -l|--languages)
      shift
      langs="-l $1"
      shift
      ;;
    --)
      shift
      break
      ;;
  esac
done

case $# in
  0);;
  1)
    FILE="$1"
    ;;
  *)
    exit_program $(basename $0)
    ;;
esac

tika_port=30000
while [ $(__NETSTAT__ -lna | egrep ":$tika_port\s" | __WC__ -l) -ne 0 ]; do
    let tika_port=$tika_port+1;
done
__JAVA__ -jar __TIKA__ -t -s $tika_port &
tika_pid=$!

trap "kill $tika_pid" TERM

check_running_tika=$(__NETSTAT__ -lna | egrep ":$tika_port\s" | __WC__ -l)
timecounter=0
while [ $check_running_tika -eq 0 ]; do
  sleep 1s;
  check_running_tika=$(__NETSTAT__ -lna | egrep ":$tika_port\s" | __WC__ -l)
  let timecounter=$timecounter+1
done


__PYTHON__ -c '
#
# 1. Read lines from .ett file
# 2. For eac line, the HTML is cleaned and the language is detected for the raw text
# 3. Output is printed following the format:
#
# language	encoding	mimetype	url	content(base_64)
#
#

import sys
import base64
from HTMLParser import HTMLParser
import langid
import argparse
import socket
import re

reload(sys)
sys.setdefaultencoding("UTF-8")

def split_obvious_paragraphs(input):
  breaking_tags=[r"(</?[Pp] *)",r"(</?[Hh][1-6] *)",r"(</?li *)",r"(</?div *)",r"(</?LI *)",r"(</?DIV *)"]
  for tag in breaking_tags:
    input=re.sub(tag, "\n"+r"\g<1>", input)
  return input

oparser = argparse.ArgumentParser(description="Script that reads the output of bitextor-webdir2ett and, for each line (lines correspond to files in de website) the language of the document is detected and this information is added to the information about the documents.")
oparser.add_argument("ett_path", metavar="FILE", nargs="?", help="File containing the output of bitextor-webdir2ett (if undefined, the script reads from the standard input)", default=None)
oparser.add_argument("-l", "--languages", help="List accepted languages represented as a comma separated language codes list", dest="langlist", default=None)
options = oparser.parse_args()

langs=[]
if options.langlist != None:
  langs=options.langlist.strip().split(",")

if options.ett_path != None:
  reader = open(options.ett_path,"r")
else:
  reader = sys.stdin

#Reading line by line from the standard output
for line in reader:
  linefields=line.strip().split()
  #decoding the b64 original webpage
  e = re.sub("\s\s+"," ",base64.b64decode(linefields[3]).replace("\n", " "))
  e = split_obvious_paragraphs(e)
  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
  s.connect(("localhost", '$tika_port'))
  s.sendall(e)
  s.shutdown(socket.SHUT_WR)
  file_output=""
  while 1:
    data = s.recv(1024)
    if data == "":
      break
    else:
      file_output=file_output+data
  s.close()
      
  parsed_text=file_output.strip()

  if len(parsed_text)>0:
    #detecting language
    lang, conf = langid.classify(parsed_text)
    if len(langs)==0 or lang in langs:
      linefields.insert(0,lang)
      e = base64.b64encode(parsed_text)
      linefields.append(e)
      print "\t".join(linefields)
      #sys.stdout.write("{0}\t{1}\t{2}\n".format(lang, "\t".join(linefields), e))' $langs < $FILE

__KILL__ $tika_pid
