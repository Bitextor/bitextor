#!__BASH__

INPUT=/dev/stdin
OUTPUT=/dev/stdout
LOG=$(mktemp /tmp/logbitextorlett2idx.XXXXXX)
TEMP=$(mktemp /tmp/bitextorlett2idx.XXXXXX)
CONT=0    # Contador para el número de documento.

exit_program()
{
  echo "USAGE: $1 file"
  echo "WHERE"
  echo "   file   file with extension .lett (language encoded and typed data)"
  exit 1
}

ARGS=$(getopt "h" $*)

set -- $ARGS
for i
do
  case "$i" in
    -h)
      exit_program $(basename $0)
      ;;
    --)
      shift
      break
      ;;
  esac
done

case $# in
  1)
    INPUT="$1"
    ;;
  *)
    exit_program $(basename $0)
    ;;
esac

# Código aquí

#
# 1. Leer .lett línea a línea
# 2. Llama a la función limpiar_texto para quitar HTML
# 3. Se separa el texto por palabras y se ordenan en minúsculas
# 4. Se saca cada palabra en un temporal con formato: language	word    num_doc
# 5. Se unifican palabras iguales que aparecen en distintos documentos
#
# Formato final del documento:
# language      word    num_doc[:inc(num_doc)]*
#
# Genera .idx -> index
#

limpiar_texto(){
  # Se coge el base64
  __GAWK__ '{print $5}' | \
  # Se decodifica el base64 y se limpia el texto con HTMLParser
  __PYTHON__ -c '
import sys
import base64
from HTMLParser import HTMLParser

class Parser(HTMLParser):

  def __init__( self ):
    HTMLParser.__init__( self )
    self.script = 0

  def handle_starttag( self, tag, attrs ):
    if tag == "script" or tag == "noscript":
      self.script = 1

  def handle_data( self, data ):
    if self.script == 0:
      sys.stdout.write(data)

  def handle_endtag( self, tag ):
    if tag == "script" or tag == "noscript":
      self.script = 0

for i in sys.stdin:
  e = base64.b64decode(i)
  Parser().feed(e)
' 2>> $LOG
}

# Para cada fichero
cat $INPUT | \
# Inicio while
while read line;
do
  # Se limpia el texto
  TEXTO=$(echo "$line" | limpiar_texto)
  # Se extrae su idioma
  IDIOMA=$(echo "$line" | __GAWK__ '{print $1}')
  # Se extraen las palabras, se ordenan y se muestran junto con el número de documento en el que aparecen.
  echo $TEXTO | \
  __GAWK__ '{print $0}' | \
__PYTHON__ -c '
import sys

for i in sys.stdin:
  campos = i.split()
  for j in campos:
    # Quito 0123456789 del filtro.
    print j.strip(",;.:-_+*\"<>|)(»«][}{?¿¡!/\\").lower()  # Hay más caracteres raros que no se pueden quitar.
' 2>> $LOG | \
# Se realiza un sort sin hacer caso del locale.
LC_COLLATE=C sort | uniq -c | \
# Se sacan a un temporal todas las palabras junto con su idioma y el número de documento en el que aparecen.
__GAWK__ -v cont=$CONT -v idioma=$IDIOMA '{
if($2 != ""){
  printf idioma "\t" $2 "\t"
  printf "%05d\n", cont}
}' >> $TEMP

  ## Contador para el número de documento.
  ((CONT++))
# Fin while
done

# Ordenar las palabras.
cat $TEMP | LC_COLLATE=C sort | __PYTHON__ -c '
import sys

anterior_id = ""
anterior_p = ""
acum = 0

for i in sys.stdin:
  campos = i.split()
  numdoc = int(campos[2])

  if anterior_id == "":
    anterior_id = campos[0]
  if campos[0] == anterior_id:
    if anterior_p == "":
      sys.stdout.write(campos[0] + "\t" + campos[1] + "\t")
      anterior_p = campos[1].lower()
      primero = True
    if campos[1].lower() == anterior_p:
      numdoc = numdoc - acum
      if primero == True:
        sys.stdout.write(campos[2])
        primero = False
      else:
        sys.stdout.write(":" + str(numdoc))
    else:
      acum = 0
      sys.stdout.write("\n" + campos[0] + "\t" + campos[1] + "\t" + str(numdoc))
      anterior_p = campos[1].lower()
      primero = False
  else:
    anterior_id = ""
  acum = acum + numdoc
' > $OUTPUT 2>> $LOG

