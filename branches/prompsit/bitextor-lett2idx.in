#!__ENV__ __PYTHON__
# -*- coding: utf-8 -*-

#
# 1. Read every line from .lett file
# 2. For each of them, clean the text and split it in words
# 3. Lowercase and create a bag of words
# 4. Creating a list with the words corresponding to every language and a list of the documents in which these words appear
#
# Output format:
# language      word    num_doc[:inc(num_doc)]*
#
# Generates .idx -> index
#

import sys
import string
import base64
from HTMLParser import HTMLParser
import argparse
import unicodedata

reload(sys)
sys.setdefaultencoding("UTF-8")

oparser = argparse.ArgumentParser(description="Script that reads the input of bitextor-ett2lett or bitextor-lett2lettr and uses the information about the files in a crawled website to produce an index with all the words in these files and the list of documents in which each of them appear")
oparser.add_argument('lett', metavar='LETT', nargs='?', help='File produced by bitextor-ett2lett or bitextor-lett2lettr containing information about the files in the website (if undefined, the script will read from the standard input)', default=None)

options = oparser.parse_args()

if options.lett != None:
  reader = open(options.lett,"r")
else:
  reader = sys.stdin

docnumber = 0
word_map = {}
unicodepunct=[]
unicodepunct.append(unicodedata.lookup("EN QUAD"))
unicodepunct.append(unicodedata.lookup("EN QUAD"))
unicodepunct.append(unicodedata.lookup("EN QUAD"))
unicodepunct.append(unicodedata.lookup("EM QUAD"))
unicodepunct.append(unicodedata.lookup("EN SPACE"))
unicodepunct.append(unicodedata.lookup("EM SPACE"))
unicodepunct.append(unicodedata.lookup("THREE-PER-EM SPACE"))
unicodepunct.append(unicodedata.lookup("FOUR-PER-EM SPACE"))
unicodepunct.append(unicodedata.lookup("SIX-PER-EM SPACE"))
unicodepunct.append(unicodedata.lookup("FIGURE SPACE"))
unicodepunct.append(unicodedata.lookup("PUNCTUATION SPACE"))
unicodepunct.append(unicodedata.lookup("THIN SPACE"))
unicodepunct.append(unicodedata.lookup("HAIR SPACE"))
unicodepunct.append(unicodedata.lookup("ZERO WIDTH SPACE"))
unicodepunct.append(unicodedata.lookup("ZERO WIDTH NON-JOINER"))
unicodepunct.append(unicodedata.lookup("ZERO WIDTH JOINER"))
unicodepunct.append(unicodedata.lookup("LEFT-TO-RIGHT MARK"))
unicodepunct.append(unicodedata.lookup("RIGHT-TO-LEFT MARK"))
unicodepunct.append(unicodedata.lookup("HYPHEN"))
unicodepunct.append(unicodedata.lookup("NON-BREAKING HYPHEN"))
unicodepunct.append(unicodedata.lookup("FIGURE DASH"))
unicodepunct.append(unicodedata.lookup("EN DASH"))
unicodepunct.append(unicodedata.lookup("EM DASH"))
unicodepunct.append(unicodedata.lookup("HORIZONTAL BAR"))
unicodepunct.append(unicodedata.lookup("DOUBLE VERTICAL LINE"))
unicodepunct.append(unicodedata.lookup("DOUBLE LOW LINE"))
unicodepunct.append(unicodedata.lookup("LEFT SINGLE QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("RIGHT SINGLE QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("SINGLE LOW-9 QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("SINGLE HIGH-REVERSED-9 QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("LEFT DOUBLE QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("RIGHT DOUBLE QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("DOUBLE LOW-9 QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("DOUBLE HIGH-REVERSED-9 QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("DAGGER"))
unicodepunct.append(unicodedata.lookup("DOUBLE DAGGER"))
unicodepunct.append(unicodedata.lookup("BULLET"))
unicodepunct.append(unicodedata.lookup("TRIANGULAR BULLET"))
unicodepunct.append(unicodedata.lookup("ONE DOT LEADER"))
unicodepunct.append(unicodedata.lookup("TWO DOT LEADER"))
unicodepunct.append(unicodedata.lookup("HORIZONTAL ELLIPSIS"))
unicodepunct.append(unicodedata.lookup("HYPHENATION POINT"))
unicodepunct.append(unicodedata.lookup("LINE SEPARATOR"))
unicodepunct.append(unicodedata.lookup("PARAGRAPH SEPARATOR"))
unicodepunct.append(unicodedata.lookup("LEFT-TO-RIGHT EMBEDDING"))
unicodepunct.append(unicodedata.lookup("RIGHT-TO-LEFT EMBEDDING"))
unicodepunct.append(unicodedata.lookup("POP DIRECTIONAL FORMATTING"))
unicodepunct.append(unicodedata.lookup("LEFT-TO-RIGHT OVERRIDE"))
unicodepunct.append(unicodedata.lookup("RIGHT-TO-LEFT OVERRIDE"))
unicodepunct.append(unicodedata.lookup("NARROW NO-BREAK SPACE"))
unicodepunct.append(unicodedata.lookup("PER MILLE SIGN"))
unicodepunct.append(unicodedata.lookup("PER TEN THOUSAND SIGN"))
unicodepunct.append(unicodedata.lookup("PRIME"))
unicodepunct.append(unicodedata.lookup("DOUBLE PRIME"))
unicodepunct.append(unicodedata.lookup("TRIPLE PRIME"))
unicodepunct.append(unicodedata.lookup("REVERSED PRIME"))
unicodepunct.append(unicodedata.lookup("REVERSED DOUBLE PRIME"))
unicodepunct.append(unicodedata.lookup("REVERSED TRIPLE PRIME"))
unicodepunct.append(unicodedata.lookup("CARET"))
unicodepunct.append(unicodedata.lookup("SINGLE LEFT-POINTING ANGLE QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("SINGLE RIGHT-POINTING ANGLE QUOTATION MARK"))
unicodepunct.append(unicodedata.lookup("REFERENCE MARK"))
unicodepunct.append(unicodedata.lookup("DOUBLE EXCLAMATION MARK"))
unicodepunct.append(unicodedata.lookup("INTERROBANG"))
unicodepunct.append(unicodedata.lookup("OVERLINE"))
unicodepunct.append(unicodedata.lookup("UNDERTIE"))
unicodepunct.append(unicodedata.lookup("CHARACTER TIE"))
unicodepunct.append(unicodedata.lookup("CARET INSERTION POINT"))
unicodepunct.append(unicodedata.lookup("ASTERISM"))
unicodepunct.append(unicodedata.lookup("HYPHEN BULLET"))
unicodepunct.append(unicodedata.lookup("FRACTION SLASH"))
unicodepunct.append(unicodedata.lookup("LEFT SQUARE BRACKET WITH QUILL"))
unicodepunct.append(unicodedata.lookup("RIGHT SQUARE BRACKET WITH QUILL"))
unicodepunct.append(unicodedata.lookup("DOUBLE QUESTION MARK"))
unicodepunct.append(unicodedata.lookup("QUESTION EXCLAMATION MARK"))
unicodepunct.append(unicodedata.lookup("EXCLAMATION QUESTION MARK"))
unicodepunct.append(unicodedata.lookup("TIRONIAN SIGN ET"))
unicodepunct.append(unicodedata.lookup("REVERSED PILCROW SIGN"))
unicodepunct.append(unicodedata.lookup("BLACK LEFTWARDS BULLET"))
unicodepunct.append(unicodedata.lookup("BLACK RIGHTWARDS BULLET"))
unicodepunct.append(unicodedata.lookup("LOW ASTERISK"))
unicodepunct.append(unicodedata.lookup("REVERSED SEMICOLON"))
unicodepunct.append(unicodedata.lookup("CLOSE UP"))
unicodepunct.append(unicodedata.lookup("TWO ASTERISKS ALIGNED VERTICALLY"))
unicodepunct.append(unicodedata.lookup("COMMERCIAL MINUS SIGN"))
unicodepunct.append(unicodedata.lookup("SWUNG DASH"))
unicodepunct.append(unicodedata.lookup("INVERTED UNDERTIE"))
unicodepunct.append(unicodedata.lookup("FLOWER PUNCTUATION MARK"))
unicodepunct.append(unicodedata.lookup("THREE DOT PUNCTUATION"))
unicodepunct.append(unicodedata.lookup("QUADRUPLE PRIME"))
unicodepunct.append(unicodedata.lookup("FOUR DOT PUNCTUATION"))
unicodepunct.append(unicodedata.lookup("FIVE DOT PUNCTUATION"))
unicodepunct.append(unicodedata.lookup("TWO DOT PUNCTUATION"))
unicodepunct.append(unicodedata.lookup("FOUR DOT MARK"))
unicodepunct.append(unicodedata.lookup("DOTTED CROSS"))
unicodepunct.append(unicodedata.lookup("TRICOLON"))
unicodepunct.append(unicodedata.lookup("VERTICAL FOUR DOTS"))
unicodepunct.append(unicodedata.lookup("MEDIUM MATHEMATICAL SPACE"))
unicodepunct.append(unicodedata.lookup("WORD JOINER"))
unicodepunct.append(unicodedata.lookup("FUNCTION APPLICATION"))
unicodepunct.append(unicodedata.lookup("INVISIBLE TIMES"))
unicodepunct.append(unicodedata.lookup("INVISIBLE SEPARATOR"))
unicodepunct.append(unicodedata.lookup("INVISIBLE PLUS"))
unicodepunct.append(unicodedata.lookup("INHIBIT SYMMETRIC SWAPPING"))
unicodepunct.append(unicodedata.lookup("ACTIVATE SYMMETRIC SWAPPING"))
unicodepunct.append(unicodedata.lookup("INHIBIT ARABIC FORM SHAPING"))
unicodepunct.append(unicodedata.lookup("ACTIVATE ARABIC FORM SHAPING"))
unicodepunct.append(unicodedata.lookup("NATIONAL DIGIT SHAPES"))
unicodepunct.append(unicodedata.lookup("NOMINAL DIGIT SHAPES"))

punctuation=string.punctuation+''.join(unicodepunct)
#sys.stderr.write(punctuation+"\n")
for line in reader:
  ##################
  #Parsing the text:
  ##################
  fields=line.strip().split("\t")
  lang=fields[0]
  #Decoding base 64:
  text = base64.b64decode(fields[5])
  #Getting the bag of words in the document
  sorted_uniq_wordlist = set(text.lower().split())
  #Trimming non-aplphanumerics:
  clean_sorted_uniq_wordlist = [w.strip(punctuation) for w in sorted_uniq_wordlist]
  sorted_uniq_wordlist=clean_sorted_uniq_wordlist

  for word in sorted_uniq_wordlist:
    if lang in word_map:
      if word in word_map[lang]:
        word_map[lang][word].append(docnumber)
      else:
        word_map[lang][word] = []
        word_map[lang][word].append(docnumber)
    else:
      word_map[lang] = {}
      word_map[lang][word] = []
      word_map[lang][word].append(docnumber)
  docnumber=docnumber+1

for map_lang, map_vocabulary in word_map.items():
  for map_word, map_doc in map_vocabulary.items():
    sorted_docs=sorted(word_map[map_lang][map_word], reverse=True)
    for doc_list_idx in range(0, len(sorted_docs)-1):
      sorted_docs[doc_list_idx]=str(sorted_docs[doc_list_idx]-sorted_docs[doc_list_idx+1])
    sorted_docs[len(sorted_docs)-1]=str(sorted_docs[len(sorted_docs)-1])
    print map_lang+"\t"+map_word+"\t"+":".join(reversed(sorted_docs))
