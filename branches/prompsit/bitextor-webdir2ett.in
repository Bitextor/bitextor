#!__BASH__

OUTPUT=/dev/stdout
TEMPCONV=$(mktemp /tmp/tempconv.XXXXX)

exit_program()
{
  echo "USAGE: $1 webdir"
  echo "WHERE"
  echo "   webdir   folder downloaded directories"
  exit 1
}

ARGS=$(getopt "h" $*)

set -- $ARGS
for i
do
  case "$i" in
    -h)
      exit_program $(basename $0)
      ;;
    --)
      shift
      break
      ;;
  esac
done

case $# in
  1)
    WEBDIR="$1"
    ;;
  *)
    exit_program $(basename $0)
    ;;
esac

tika_port=10000
while [ $(__LSOF__ -i :$tika_port | __WC__ -l) -ne 0 ]; do
    let tika_port=$tika_port+1;
done
__JAVA__ -jar __TIKA__ --xml -s $tika_port &
tika_pid=$!

check_running_tika=$(__LSOF__ -i :$tika_port | __WC__ -l)
timecounter=0
while [ $check_running_tika -eq 0 ]; do
  sleep 1s;
  check_running_tika=$(__LSOF__ -i :$tika_port | __WC__ -l)
  let timecounter=$timecounter+1
done

# Código aquí

#
# 1. Eliminar ficheros repetidos -> (log)
# 2. Obtener tipo y codificación de ficheros
# 3. Quedarse solo con los que tengan tipo html
# 4. Convertir [no UTF-8 -> UTF-8], si hay error -> (log)
# 5. Corregir errores HTML usando Tidy y eliminar las cabeceras HTML
# 6. Incluir el contenido del fichero en base64
#
# Formato final del documento:
# encoding	mimetype	url	content(base_64)
#
# Genera .ett -> encoded and typed text
#

# Not empty files are searched in WEBDIR and they are printer together with their mime type and their encoding
find "$WEBDIR" -type f -exec file -N --mime-type --mime-encoding {} + | \
/usr/bin/gawk '{
  if ( match($2, "text/.*") != 0 ){
    printf substr($1,1,length($1)-1);    # nombre_fichero
    printf "\t";
    printf substr($2,1,length($2)-1);    # formato: text/html etc.
    printf "\t";
    print substr($3,9,length($3));       # encoding
  }
}' | \
# Se pasan a md5
__PYTHON__ -c 'import sys
import hashlib
import os
import base64
import socket
from boilerpipe.extract import Extractor

reload(sys)
sys.setdefaultencoding("UTF-8")

seen_md5=[]
for i in sys.stdin:
  fields = i.split()
  file = open(fields[0], "r")  # la i es el nombre del fichero
  c = hashlib.md5()
  #Computing md5 for the file
  for j in file:
    c.update(j)
  file.close()
  #Checking for duplicates
  if c.hexdigest() in seen_md5:
    sys.stderr.write("Eliminando repetido:\t"+fields[0]+"\n")
  else:
    file = open(fields[0], "r")
    extractor = Extractor(extractor="ArticleExtractor", html=file.read())
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.connect(("localhost", '$tika_port'))
    s.sendall(extractor.getHTML())
    s.shutdown(socket.SHUT_WR)
    file_output=""
    while 1:
      data = s.recv(1024)
      if data == "":
        break
      else:
        file_output=file_output+data
    s.close()

    e = base64.b64encode(file_output)
    #Por último, guardamos los datos en un mismo fichero con el formato: encoding   formato   nombre_fichero   base64
    print "{0}\t{1}\t{2}\t{3}".format(fields[2].strip(),fields[1],os.path.relpath(fields[0],sys.argv[1]),e)
    file.close()
' $WEBDIR > $OUTPUT

rm -Rf $TEMPCONV

__KILL__ $tika_pid

