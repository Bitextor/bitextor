#!__ENV__ __PYTHON__

#
# 1. Read lines from .ett file
# 2. For eac line, the HTML is cleaned and the language is detected for the raw text
# 3. Output is printed following the format:
#
# language	encoding	mimetype	url	content(base_64)
#
#

import sys
import base64
from HTMLParser import HTMLParser
import langid
import argparse

reload(sys)
sys.setdefaultencoding("UTF-8")

class Parser(HTMLParser):

  def __init__( self ):
    HTMLParser.__init__( self )
    self.contains1 = ("h1", "h2", "h3", "h4")
    self.contains2 = ("p", "li", "a")
    self.script = 0
    self.include1 = 0
    self.include2 = 0
    self.output = []

  def handle_starttag( self, tag, attrs ):
    if tag == "script" or tag == "noscript":
      self.script = 1
    if self.script == 0:
      if tag in self.contains1:
        self.include1 = 1
      elif tag in self.contains2:
        self.include2 += 1

  def handle_data( self, data ):
    if self.script == 0:
      if self.include1 == 1:
        if len(data.split()) > 0:
          if data.strip()[-1] == ".":
            self.output.append(data + "\n")
          else:
            self.output.append(data + ".\n")
      elif self.include2 > 0:
        palabras = len(data.split())
        if palabras > 4:
          if data.strip()[-1] == ".":
            self.output.append(data + "\n")
          else:
            self.output.append(data + ".\n")

  def handle_endtag( self, tag ):
    if tag == "script" or tag == "noscript":
      self.script = 0
    if self.script == 0:
      if tag in self.contains1:
        self.include1 = 0
      elif tag in self.contains2:
        self.include2 -= 1

oparser = argparse.ArgumentParser(description="Script that reads the output of bitextor-webdir2ett and, for each line (lines correspond to files in de website) the language of the document is detected and this information is added to the information about the documents.")
oparser.add_argument('ett_path', metavar='FILE', nargs='?', help='File containing the output of bitextor-webdir2ett (if undefined, the script reads from the standard input)', default=None)
oparser.add_argument("-l", "--languages", help="List accepted languages represented as a comma separated language codes list", dest="langlist", default=None)
options = oparser.parse_args()

langs=[]
if options.langlist != None:
  langs=options.langlist.strip().split(",")

if options.ett_path != None:
  reader = open(options.ett_path,"r")
else:
  reader = sys.stdin

#Reading line by line from the standard output
for line in reader:
  linefields=line.strip().split()
  #decoding the b64 original webpage
  e = base64.b64decode(linefields[3]).replace("\n", " ")
  p=Parser()
  p.feed(e)
  parsed_text=" ".join(p.output)
  if len(parsed_text)>0:
    #detecting language
    lang, conf = langid.classify(parsed_text)
    if len(langs)==0 or lang in langs:
      linefields.insert(0,lang)
      e = base64.b64encode(parsed_text)
      linefields.append(e)
      print "\t".join(linefields)
      #sys.stdout.write("{0}\t{1}\t{2}\n".format(lang, "\t".join(linefields), e))
